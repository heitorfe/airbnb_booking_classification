{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffcf71b",
   "metadata": {},
   "source": [
    "**Business Problem**\n",
    "\n",
    "New users on Airbnb can book a place to stay in 34,000+ cities across 190+ countries. By accurately predicting where a new user will book their first travel experience, Airbnb can share more personalized content with their community, decrease the average time to first booking, and better forecast demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec228b9b",
   "metadata": {},
   "source": [
    "**Data Description**\n",
    "\n",
    "In this challenge, you are given a list of users along with their demographics, web session records, and some summary statistics. You are asked to predict which country a new user's first booking destination will be. All the users in this dataset are from the USA.\n",
    "\n",
    "There are 12 possible outcomes of the destination country: 'US', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU', 'NDF' (no destination found), and 'other'. Please note that 'NDF' is different from 'other' because 'other' means there was a booking, but is to a country not included in the list, while 'NDF' means there wasn't a booking.\n",
    "\n",
    "The training and test sets are split by dates. In the test set, you will predict all the new users with first activities after 7/1/2014 (note: this is updated on 12/5/15 when the competition restarted). In the sessions dataset, the data only dates back to 1/1/2014, while the users dataset dates back to 2010. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3bae8",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "1. Predict and load in a database, use data visualization to see results\n",
    "\n",
    "2. API: \n",
    "    * Input: id and customer features\n",
    "    * Output: id + predict + probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ed7c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:09:34.470820Z",
     "start_time": "2023-06-16T22:09:34.436297Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "class Airbnb:\n",
    "\n",
    "    def load_data(self):\n",
    "        df_raw = pd.read_csv('../data/train_users_2.csv', low_memory=True)\n",
    "        df_sessions = pd.read_csv('../data/sessions.csv')\n",
    "        return df_raw, df_sessions\n",
    "\n",
    "\n",
    "    def transform_data(self, df, df_sessions):\n",
    "        #==================Training================\n",
    "        #age\n",
    "        age_mean = df['age'].mean()\n",
    "        df['age'] = df['age'].fillna(age_mean)\n",
    "\n",
    "        # first_affiliate_tracked\n",
    "        df['first_affiliate_tracked'].dropna(inplace=True)\n",
    "\n",
    "        #==================Sessions==============\n",
    "        df_sessions.dropna(inplace = True)\n",
    "\n",
    "        #date_account_created\n",
    "        df['date_account_created'] = pd.to_datetime(df['date_account_created'])\n",
    "\n",
    "        #timestamp_first_active\n",
    "        df['timestamp_first_active'] = pd.to_datetime(df['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "        # date_first_booking - not available\n",
    "        df.drop('date_first_booking', axis = 1, inplace = True)\n",
    "\n",
    "        #age\n",
    "        df['age'] = df['age'].astype('int64')\n",
    "\n",
    "        #Filter\n",
    "        df = df[(df['age']>15) & (df['age']<100)]\n",
    "\n",
    "        return df, df_sessions\n",
    "\n",
    "\n",
    "    def feature_engineering(self, df, df_sessions):\n",
    "\n",
    "        df['first_active'] = pd.to_datetime(df['timestamp_first_active'].dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "        #time between account created and first active\n",
    "        df['days_from_active_to_account_created'] = (df['date_account_created'] - df['first_active']).dt.days\n",
    "\n",
    "        #year  of first active\n",
    "        df['year_first_active'] = df['first_active'].dt.year\n",
    "\n",
    "        #month of first active\n",
    "        df['month_first_active'] = df['first_active'].dt.month\n",
    "\n",
    "        #day of first active\n",
    "        df['day_first_active'] = df['first_active'].dt.day\n",
    "\n",
    "        #day of week of first active\n",
    "        df['day_of_week_first_active'] = df['first_active'].dt.dayofweek\n",
    "\n",
    "        #week of year of first active\n",
    "        df['week_of_year_first_active'] = df['first_active'].dt.isocalendar().week\n",
    "\n",
    "        #year  of account created\n",
    "        df['year_account_created'] = df['date_account_created'].dt.year\n",
    "\n",
    "        #month of account created\n",
    "        df['month_account_created'] = df['date_account_created'].dt.month\n",
    "\n",
    "        #day of account created\n",
    "        df['day_account_created'] = df['date_account_created'].dt.day\n",
    "\n",
    "        #day of week of account created\n",
    "        df['day_of_week_account_created'] = df['date_account_created'].dt.dayofweek\n",
    "\n",
    "        #week of year of account created\n",
    "        df['week_of_year_account_created'] = df['date_account_created'].dt.isocalendar().week\n",
    "\n",
    "        # n_clicks\n",
    "        n_clicks = df_sessions[df_sessions['action_type']=='click'].groupby('user_id').agg(n_clicks = ('user_id', 'count')).reset_index()\n",
    "        df = pd.merge(df, n_clicks.rename(columns = {'user_id' : 'id'}), on ='id', how='left')\n",
    "        df['n_clicks'].fillna(0, inplace=True)\n",
    "\n",
    "        n_reviews = df_sessions[df_sessions['action']=='reviews'].groupby('user_id').agg(n_reviews = ('user_id', 'count')).reset_index()\n",
    "        df = pd.merge(df, n_reviews.rename(columns = {'user_id' : 'id'}), on ='id', how='left')\n",
    "        df['n_reviews'].fillna(0, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def data_preprocessing(self, df):\n",
    "        \n",
    "        # language to binary, either is english or not\n",
    "        df['language_en'] = np.where(df['language']=='en', 1, 0)\n",
    "\n",
    "        # signup to binary, either is web or not\n",
    "        df['signup_on_web'] = np.where(df['signup_app']== 'Web', 1, 0)\n",
    "\n",
    "        # first_affiliate_tracked to binary, either is tracked or not\n",
    "        df['tracked'] = np.where(df['first_affiliate_tracked']=='untracked', 0, 1)\n",
    "\n",
    "        #binary features from first_device_type\n",
    "        df['first_device_apple'] = np.where(df['first_device_type'].isin(['Mac Desktop', 'iPhone', 'iPad']), 1 ,0)\n",
    "        df['first_device_desktop'] = np.where(df['first_device_type'].isin(['Mac Desktop', 'Desktop', 'Windows Desktop']), 1, 0)\n",
    "\n",
    "        # frequency encoding\n",
    "        affiliate_channel_frequency_encoding = df['affiliate_channel'].value_counts(normalize=True)\n",
    "        df['affiliate_channel'] = df['affiliate_channel'].map(affiliate_channel_frequency_encoding)\n",
    "\n",
    "        affiliate_provider_frequency_encoding = df['affiliate_provider'].value_counts(normalize=True)\n",
    "        df['affiliate_provider'] = df['affiliate_provider'].map(affiliate_provider_frequency_encoding)\n",
    "\n",
    "        first_browser_frequency_encoding = df['first_browser'].value_counts(normalize=True)\n",
    "        df['first_browser'] = df['first_browser'].map(first_browser_frequency_encoding)\n",
    "\n",
    "        # Rescaling\n",
    "        columns_to_rescale = [\n",
    "        \"age\",\n",
    "        \"signup_flow\",\n",
    "        \"n_reviews\",\n",
    "        \"n_clicks\"\n",
    "        ]\n",
    "\n",
    "        scaler = pp.MinMaxScaler()\n",
    "        df[columns_to_rescale] = scaler.fit_transform(df[columns_to_rescale])\n",
    "\n",
    "         # month_account_created\n",
    "        df['month_account_created_sin'] = df['month_account_created'].apply( lambda x: np.sin( x * (2*np.pi/12 ) ) )\n",
    "        df['month_account_created_cos'] = df['month_account_created'].apply( lambda x: np.cos( x * (2*np.pi/12 ) ) )\n",
    "\n",
    "        # week_account_created\n",
    "        df['week_account_created_sin'] = df['week_of_year_account_created'].apply( lambda x: np.sin( x * (2*np.pi/52 ) ) )\n",
    "        df['week_account_created_cos'] = df['week_of_year_account_created'].apply( lambda x: np.cos( x * (2*np.pi/52 ) ) )\n",
    "\n",
    "        # day_account_created\n",
    "        df['day_account_created_sin'] = df['day_account_created'].apply( lambda x: np.sin( x * (2*np.pi/30 ) ) )\n",
    "        df['day_account_created_cos'] = df['day_account_created'].apply( lambda x: np.cos( x * (2*np.pi/30 ) ) )\n",
    "\n",
    "        # day_of_week_account_created\n",
    "        df['day_of_week_account_created_sin'] = df['day_of_week_account_created'].apply( lambda x: np.sin( x * (2*np.pi/7 ) ) )\n",
    "        df['day_of_week_account_created_cos'] = df['day_of_week_account_created'].apply( lambda x: np.cos( x * (2*np.pi/7 ) ) )\n",
    "\n",
    "        X = df[['age', 'signup_flow', 'affiliate_channel', 'affiliate_provider',\n",
    "                 'first_browser', 'n_clicks', 'n_reviews',\n",
    "                 'language_en', 'signup_on_web', 'tracked', 'first_device_apple',\n",
    "                 'first_device_desktop', 'month_account_created_sin',\n",
    "                 'month_account_created_cos', 'week_account_created_sin',\n",
    "                 'week_account_created_cos', 'day_account_created_sin',\n",
    "                 'day_account_created_cos', 'day_of_week_account_created_sin',\n",
    "                 'day_of_week_account_created_cos']]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def balance_data(self, X_imb, y_imb):\n",
    "\n",
    "        majority_value = y.value_counts()[0]\n",
    "\n",
    "        # Calcular os pesos de classe inversamente proporcionais à frequência\n",
    "        class_weights = {'NDF': majority_value*1,\n",
    "                         'US': int(majority_value*0.5),\n",
    "                         'other': int(majority_value*0.18),\n",
    "                         'FR': int(majority_value*0.15) ,\n",
    "                         'IT': int(majority_value*0.13),\n",
    "                         'GB': int(majority_value*0.13),\n",
    "                         'ES': int(majority_value*0.13),\n",
    "                         'CA': int(majority_value*0.13),\n",
    "                         'DE': int(majority_value*0.13),\n",
    "                         'NL': int(majority_value*0.09),\n",
    "                         'AU': int(majority_value*0.09),\n",
    "                         'PT': int(majority_value*0.09)\n",
    "                        }\n",
    "\n",
    "        # Instanciar o SMOTE com os pesos de classe definidos\n",
    "        smote = BorderlineSMOTE(sampling_strategy=class_weights)\n",
    "\n",
    "        # Aplicar o resampling usando o SMOTE\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "    def train_model(self, model, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, y, train_size = 0.8, random_state=42)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        \n",
    "        if not os.path.exists('../models/'):\n",
    "            os.mkdir('../models/')\n",
    "            \n",
    "        joblib.dump( model, \"../model/extratrees.joblib\", compress=3 ) \n",
    "\n",
    "    def predict(self, model, X_test):\n",
    "        \n",
    "        return model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835de324",
   "metadata": {},
   "source": [
    "### Pipeline - Train and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e809b048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:10:53.752700Z",
     "start_time": "2023-06-16T22:09:49.109169Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Airbnb()\n",
    "\n",
    "df_raw, df_sessions = pipeline.load_data()\n",
    "\n",
    "df, df_sessions = pipeline.transform_data(df_raw, df_sessions)\n",
    "\n",
    "df = pipeline.feature_engineering(df, df_sessions)\n",
    "\n",
    "y = df['country_destination']\n",
    "\n",
    "X = pipeline.data_preprocessing(df)\n",
    "\n",
    "X_balanced, y_balanced = pipeline.balance_data(X, y)\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=10)\n",
    "\n",
    "extra_trees = pipeline.train_model(extra_trees, X_balanced, y_balanced)\n",
    "\n",
    "pipeline.dump_model(extra_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c78b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:52:14.760619Z",
     "start_time": "2023-06-13T17:52:14.750584Z"
    }
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2754c847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:28.438908Z",
     "start_time": "2023-06-16T22:11:27.267091Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pipeline = Airbnb()\n",
    "\n",
    "model = joblib.load('../model/extratrees.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f2baf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:30.245444Z",
     "start_time": "2023-06-16T22:11:30.123084Z"
    }
   },
   "outputs": [],
   "source": [
    "#### input test\n",
    "test = pd.read_csv('../data/test_users.csv')\n",
    "json_data = test.head().to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77d3b203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:30.603338Z",
     "start_time": "2023-06-16T22:11:30.587687Z"
    }
   },
   "outputs": [],
   "source": [
    "json_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76d13f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:30.972908Z",
     "start_time": "2023-06-16T22:11:30.949613Z"
    }
   },
   "outputs": [],
   "source": [
    "if json_data:\n",
    "    df_raw = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01570628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:37.709925Z",
     "start_time": "2023-06-16T22:11:31.438722Z"
    }
   },
   "outputs": [],
   "source": [
    "_, df_sessions = pipeline.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfc8b1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:47.349912Z",
     "start_time": "2023-06-16T22:11:39.607669Z"
    }
   },
   "outputs": [],
   "source": [
    "df, df_sessions = pipeline.transform_data(df_raw, df_sessions)\n",
    "\n",
    "df = pipeline.feature_engineering(df, df_sessions)\n",
    "\n",
    "X = pipeline.data_preprocessing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85d3dae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:48.843843Z",
     "start_time": "2023-06-16T22:11:48.825140Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_country_destinations_proba = pipeline.predict(model, X)\n",
    "\n",
    "classes = model.classes_\n",
    "predicted_classes = np.argmax(predicted_country_destinations_proba, axis=1)\n",
    "class_proba = np.max(predicted_country_destinations_proba, axis=1)\n",
    "predicted_class_names = [classes[i] for i in predicted_classes]\n",
    "\n",
    "df['country_destination'] = predicted_class_names\n",
    "df['proba'] = class_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87639fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T22:11:50.525849Z",
     "start_time": "2023-06-16T22:11:50.497401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>...</th>\n",
       "      <th>month_account_created_sin</th>\n",
       "      <th>month_account_created_cos</th>\n",
       "      <th>week_account_created_sin</th>\n",
       "      <th>week_account_created_cos</th>\n",
       "      <th>day_account_created_sin</th>\n",
       "      <th>day_account_created_cos</th>\n",
       "      <th>day_of_week_account_created_sin</th>\n",
       "      <th>day_of_week_account_created_cos</th>\n",
       "      <th>country_destination</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:00:06</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>US</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:00:51</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>US</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:01:48</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:02:15</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:03:05</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>US</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created timestamp_first_active     gender  age  \\\n",
       "0  5uwns89zht           2014-07-01    2014-07-01 00:00:06     FEMALE  0.0   \n",
       "1  jtl0dijy2j           2014-07-01    2014-07-01 00:00:51  -unknown-  0.0   \n",
       "2  xx0ulgorjt           2014-07-01    2014-07-01 00:01:48  -unknown-  0.0   \n",
       "3  6c6puo6ix0           2014-07-01    2014-07-01 00:02:15  -unknown-  0.0   \n",
       "4  czqhjk3yfe           2014-07-01    2014-07-01 00:03:05  -unknown-  0.0   \n",
       "\n",
       "  signup_method  signup_flow language  affiliate_channel  affiliate_provider  \\\n",
       "0      facebook          0.0       en                1.0                 1.0   \n",
       "1         basic          0.0       en                1.0                 1.0   \n",
       "2         basic          0.0       en                1.0                 1.0   \n",
       "3         basic          0.0       en                1.0                 1.0   \n",
       "4         basic          0.0       en                1.0                 1.0   \n",
       "\n",
       "   ... month_account_created_sin month_account_created_cos  \\\n",
       "0  ...                      -0.5                 -0.866025   \n",
       "1  ...                      -0.5                 -0.866025   \n",
       "2  ...                      -0.5                 -0.866025   \n",
       "3  ...                      -0.5                 -0.866025   \n",
       "4  ...                      -0.5                 -0.866025   \n",
       "\n",
       "  week_account_created_sin  week_account_created_cos day_account_created_sin  \\\n",
       "0                -0.120537                 -0.992709                0.207912   \n",
       "1                -0.120537                 -0.992709                0.207912   \n",
       "2                -0.120537                 -0.992709                0.207912   \n",
       "3                -0.120537                 -0.992709                0.207912   \n",
       "4                -0.120537                 -0.992709                0.207912   \n",
       "\n",
       "   day_account_created_cos  day_of_week_account_created_sin  \\\n",
       "0                 0.978148                         0.781831   \n",
       "1                 0.978148                         0.781831   \n",
       "2                 0.978148                         0.781831   \n",
       "3                 0.978148                         0.781831   \n",
       "4                 0.978148                         0.781831   \n",
       "\n",
       "   day_of_week_account_created_cos  country_destination  proba  \n",
       "0                          0.62349                   US    0.3  \n",
       "1                          0.62349                   US    0.3  \n",
       "2                          0.62349                   CA    0.5  \n",
       "3                          0.62349                   CA    0.4  \n",
       "4                          0.62349                   US    0.5  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
