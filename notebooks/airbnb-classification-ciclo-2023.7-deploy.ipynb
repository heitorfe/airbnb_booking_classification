{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffcf71b",
   "metadata": {},
   "source": [
    "**Business Problem**\n",
    "\n",
    "New users on Airbnb can book a place to stay in 34,000+ cities across 190+ countries. By accurately predicting where a new user will book their first travel experience, Airbnb can share more personalized content with their community, decrease the average time to first booking, and better forecast demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec228b9b",
   "metadata": {},
   "source": [
    "**Data Description**\n",
    "\n",
    "In this challenge, you are given a list of users along with their demographics, web session records, and some summary statistics. You are asked to predict which country a new user's first booking destination will be. All the users in this dataset are from the USA.\n",
    "\n",
    "There are 12 possible outcomes of the destination country: 'US', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU', 'NDF' (no destination found), and 'other'. Please note that 'NDF' is different from 'other' because 'other' means there was a booking, but is to a country not included in the list, while 'NDF' means there wasn't a booking.\n",
    "\n",
    "The training and test sets are split by dates. In the test set, you will predict all the new users with first activities after 7/1/2014 (note: this is updated on 12/5/15 when the competition restarted). In the sessions dataset, the data only dates back to 1/1/2014, while the users dataset dates back to 2010. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3bae8",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "1. Predict and load in a database, use data visualization to see results\n",
    "\n",
    "2. API: \n",
    "    * Input: id and customer features\n",
    "    * Output: id + predict + probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ed7c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:08:48.726686Z",
     "start_time": "2023-06-14T09:08:48.653896Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "class Airbnb:\n",
    "\n",
    "    def load_data(self):\n",
    "        df_raw = pd.read_csv('../data/train_users_2.csv', low_memory=True)\n",
    "        df_sessions = pd.read_csv('../data/sessions.csv')\n",
    "        return df_raw, df_sessions\n",
    "\n",
    "\n",
    "    def transform_data(self, df, df_sessions):\n",
    "        #==================Training================\n",
    "\n",
    "        #age\n",
    "        age_mean = df['age'].mean()\n",
    "        df['age'] = df['age'].fillna(age_mean)\n",
    "\n",
    "        # first_affiliate_tracked\n",
    "        df['first_affiliate_tracked'].dropna(inplace=True)\n",
    "\n",
    "        #==================Sessions==============\n",
    "        df_sessions.dropna(inplace = True)\n",
    "\n",
    "        #date_account_created\n",
    "        df['date_account_created'] = pd.to_datetime(df['date_account_created'])\n",
    "\n",
    "        #timestamp_first_active\n",
    "        df['timestamp_first_active'] = pd.to_datetime(df['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "        # date_first_booking - not available\n",
    "        df.drop('date_first_booking', axis = 1, inplace = True)\n",
    "\n",
    "        #age\n",
    "        df['age'] = df['age'].astype('int64')\n",
    "\n",
    "        #Filter\n",
    "        df = df[(df['age']>15) & (df['age']<100)]\n",
    "\n",
    "        return df, df_sessions\n",
    "\n",
    "\n",
    "    def feature_engineering(self, df, df_sessions):\n",
    "\n",
    "        df['first_active'] = pd.to_datetime(df['timestamp_first_active'].dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "        #time between account created and first active\n",
    "        df['days_from_active_to_account_created'] = (df['date_account_created'] - df['first_active']).dt.days\n",
    "\n",
    "        #year  of first active\n",
    "        df['year_first_active'] = df['first_active'].dt.year\n",
    "\n",
    "        #month of first active\n",
    "        df['month_first_active'] = df['first_active'].dt.month\n",
    "\n",
    "        #day of first active\n",
    "        df['day_first_active'] = df['first_active'].dt.day\n",
    "\n",
    "        #day of week of first active\n",
    "        df['day_of_week_first_active'] = df['first_active'].dt.dayofweek\n",
    "\n",
    "        #week of year of first active\n",
    "        df['week_of_year_first_active'] = df['first_active'].dt.isocalendar().week\n",
    "\n",
    "\n",
    "        #year  of account created\n",
    "        df['year_account_created'] = df['date_account_created'].dt.year\n",
    "\n",
    "        #month of account created\n",
    "        df['month_account_created'] = df['date_account_created'].dt.month\n",
    "\n",
    "        #day of account created\n",
    "        df['day_account_created'] = df['date_account_created'].dt.day\n",
    "\n",
    "        #day of week of account created\n",
    "        df['day_of_week_account_created'] = df['date_account_created'].dt.dayofweek\n",
    "\n",
    "        #week of year of account created\n",
    "        df['week_of_year_account_created'] = df['date_account_created'].dt.isocalendar().week\n",
    "\n",
    "        # n_clicks\n",
    "        n_clicks = df_sessions[df_sessions['action_type']=='click'].groupby('user_id').agg(n_clicks = ('user_id', 'count')).reset_index()\n",
    "        df = pd.merge(df, n_clicks.rename(columns = {'user_id' : 'id'}), on ='id', how='left')\n",
    "        df['n_clicks'].fillna(0, inplace=True)\n",
    "\n",
    "        n_reviews = df_sessions[df_sessions['action']=='reviews'].groupby('user_id').agg(n_reviews = ('user_id', 'count')).reset_index()\n",
    "        df = pd.merge(df, n_reviews.rename(columns = {'user_id' : 'id'}), on ='id', how='left')\n",
    "        df['n_reviews'].fillna(0, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def data_preprocessing(self, df):\n",
    "        #dummy variable - signup_method\n",
    "    #     dummy = pd.get_dummies(df['signup_method'])\n",
    "    #     df = pd.concat([df, dummy], axis=1)\n",
    "\n",
    "        # language to binary, either is english or not\n",
    "        df['language_en'] = np.where(df['language']=='en', 1, 0)\n",
    "\n",
    "        # signup to binary, either is web or not\n",
    "        df['signup_on_web'] = np.where(df['signup_app']== 'Web', 1, 0)\n",
    "\n",
    "        # first_affiliate_tracked to binary, either is tracked or not\n",
    "        df['tracked'] = np.where(df['first_affiliate_tracked']=='untracked', 0, 1)\n",
    "\n",
    "        #binary features from first_device_type\n",
    "        df['first_device_apple'] = np.where(df['first_device_type'].isin(['Mac Desktop', 'iPhone', 'iPad']), 1 ,0)\n",
    "        df['first_device_desktop'] = np.where(df['first_device_type'].isin(['Mac Desktop', 'Desktop', 'Windows Desktop']), 1, 0)\n",
    "\n",
    "        # frequency encoding\n",
    "        affiliate_channel_frequency_encoding = df['affiliate_channel'].value_counts(normalize=True)\n",
    "        df['affiliate_channel'] = df['affiliate_channel'].map(affiliate_channel_frequency_encoding)\n",
    "\n",
    "        affiliate_provider_frequency_encoding = df['affiliate_provider'].value_counts(normalize=True)\n",
    "        df['affiliate_provider'] = df['affiliate_provider'].map(affiliate_provider_frequency_encoding)\n",
    "\n",
    "        first_browser_frequency_encoding = df['first_browser'].value_counts(normalize=True)\n",
    "        df['first_browser'] = df['first_browser'].map(first_browser_frequency_encoding)\n",
    "\n",
    "        # Rescaling\n",
    "        columns_to_rescale = [\n",
    "        \"age\",\n",
    "        \"signup_flow\",\n",
    "        \"n_reviews\",\n",
    "        \"n_clicks\"\n",
    "        ]\n",
    "\n",
    "        scaler = pp.MinMaxScaler()\n",
    "\n",
    "        df[columns_to_rescale] = scaler.fit_transform(df[columns_to_rescale])\n",
    "\n",
    "        # temporal columns \n",
    "        temporal_columns = [\n",
    "        \"days_from_active_to_account_created\",\n",
    "        \"year_first_active\",\n",
    "        \"month_first_active\",\n",
    "        \"day_first_active\",\n",
    "        \"day_of_week_first_active\",\n",
    "        \"week_of_year_first_active\",\n",
    "        \"year_account_created\",\n",
    "        \"month_account_created\",\n",
    "        \"day_account_created\",\n",
    "        \"day_of_week_account_created\",\n",
    "        \"week_of_year_account_created\"]\n",
    "\n",
    "         # month_account_created\n",
    "        df['month_account_created_sin'] = df['month_account_created'].apply( lambda x: np.sin( x * (2*np.pi/12 ) ) )\n",
    "        df['month_account_created_cos'] = df['month_account_created'].apply( lambda x: np.cos( x * (2*np.pi/12 ) ) )\n",
    "\n",
    "        # week_account_created\n",
    "        df['week_account_created_sin'] = df['week_of_year_account_created'].apply( lambda x: np.sin( x * (2*np.pi/52 ) ) )\n",
    "        df['week_account_created_cos'] = df['week_of_year_account_created'].apply( lambda x: np.cos( x * (2*np.pi/52 ) ) )\n",
    "\n",
    "        # day_account_created\n",
    "        df['day_account_created_sin'] = df['day_account_created'].apply( lambda x: np.sin( x * (2*np.pi/30 ) ) )\n",
    "        df['day_account_created_cos'] = df['day_account_created'].apply( lambda x: np.cos( x * (2*np.pi/30 ) ) )\n",
    "\n",
    "        # day_of_week_account_created\n",
    "        df['day_of_week_account_created_sin'] = df['day_of_week_account_created'].apply( lambda x: np.sin( x * (2*np.pi/7 ) ) )\n",
    "        df['day_of_week_account_created_cos'] = df['day_of_week_account_created'].apply( lambda x: np.cos( x * (2*np.pi/7 ) ) )\n",
    "\n",
    "\n",
    "        df.drop(temporal_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        cols_drop = [ 'gender', 'signup_method', 'language', 'first_affiliate_tracked',\n",
    "               'signup_app', 'first_device_type','date_account_created', 'timestamp_first_active',\n",
    "                      'first_active'] #original dates\n",
    "        df = df.drop(cols_drop, axis=1)\n",
    "        return df\n",
    "\n",
    "    def balance_data(self, X_imb, y_imb):\n",
    "\n",
    "        majority_value = y.value_counts()[0]\n",
    "\n",
    "        # Calcular os pesos de classe inversamente proporcionais à frequência\n",
    "        class_weights = {'NDF': majority_value*1,\n",
    "                         'US': int(majority_value*0.5),\n",
    "                         'other': int(majority_value*0.18),\n",
    "                         'FR': int(majority_value*0.15) ,\n",
    "                         'IT': int(majority_value*0.13),\n",
    "                         'GB': int(majority_value*0.13),\n",
    "                         'ES': int(majority_value*0.13),\n",
    "                         'CA': int(majority_value*0.13),\n",
    "                         'DE': int(majority_value*0.13),\n",
    "                         'NL': int(majority_value*0.09),\n",
    "                         'AU': int(majority_value*0.09),\n",
    "                         'PT': int(majority_value*0.09)\n",
    "                        }\n",
    "\n",
    "        # Instanciar o SMOTE com os pesos de classe definidos\n",
    "        smote = BorderlineSMOTE(sampling_strategy=class_weights)\n",
    "\n",
    "        # Aplicar o resampling usando o SMOTE\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "    def train_model(self, model, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, y, train_size = 0.8, random_state=42)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        \n",
    "        if not os.path.exists('../models/'):\n",
    "            os.mkdir('../models/')\n",
    "            \n",
    "        pickle.dump(model, open('../models/extratrees.pkl', 'wb'))\n",
    "        joblib.dump( model, \"../models/extratrees.joblib\", compress=3 ) \n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        joblib.dump( model_rf, \"../model/full_rf_model_compressed.joblib\", compress=3 ) \n",
    "        print( f\"Random Forest full size: {np.round(ops.path.getsize('../model/full_rf_model_compressed.joblib') / 1024 / 1024, 2) } MB\")\n",
    "\n",
    "    \n",
    "    def predict(self, model, X_test):\n",
    "        \n",
    "        return model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835de324",
   "metadata": {},
   "source": [
    "### Pipeline - Train and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e809b048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:08:56.476189Z",
     "start_time": "2023-06-14T09:08:51.212996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Airbnb()\n",
    "\n",
    "df_raw, df_sessions = pipeline.load_data()\n",
    "\n",
    "df, df_sessions = pipeline.transform_data(df_raw, df_sessions)\n",
    "\n",
    "df = pipeline.feature_engineering(df, df_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fb9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:08:56.480812Z",
     "start_time": "2023-06-14T09:08:56.480812Z"
    }
   },
   "outputs": [],
   "source": [
    "df= pipeline.data_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "973d685d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T18:54:07.530275Z",
     "start_time": "2023-06-13T18:52:54.064389Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['country_destination', 'id'], axis=1)\n",
    "y = df['country_destination']\n",
    "\n",
    "X_balanced, y_balanced = pipeline.balance_data(X, y)\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=10)\n",
    "\n",
    "extra_trees = pipeline.train_model(extra_trees, X_balanced, y_balanced)\n",
    "\n",
    "pipeline.dump_model(extra_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c78b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:52:14.760619Z",
     "start_time": "2023-06-13T17:52:14.750584Z"
    }
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2754c847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:02.048941Z",
     "start_time": "2023-06-14T09:08:58.790917Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pipeline = Airbnb()\n",
    "\n",
    "model = joblib.load('../models/extratrees.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2f2baf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:02.980973Z",
     "start_time": "2023-06-14T09:09:02.677359Z"
    }
   },
   "outputs": [],
   "source": [
    "#### input test\n",
    "test = pd.read_csv('../data/test_users.csv')\n",
    "json_data = test.head().to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d3b203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:03.793715Z",
     "start_time": "2023-06-14T09:09:03.786123Z"
    }
   },
   "outputs": [],
   "source": [
    "json_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d13f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:05.530776Z",
     "start_time": "2023-06-14T09:09:05.520919Z"
    }
   },
   "outputs": [],
   "source": [
    "if json_data:\n",
    "    df_raw = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01570628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:23.492896Z",
     "start_time": "2023-06-14T09:09:06.291273Z"
    }
   },
   "outputs": [],
   "source": [
    "_, df_sessions = pipeline.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8b1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:09:44.804203Z",
     "start_time": "2023-06-14T09:09:23.493234Z"
    }
   },
   "outputs": [],
   "source": [
    "df, df_sessions = pipeline.transform_data(df_raw, df_sessions)\n",
    "\n",
    "df = pipeline.feature_engineering(df, df_sessions)\n",
    "\n",
    "df= pipeline.data_preprocessing(df)\n",
    "X = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d3dae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T09:14:34.887455Z",
     "start_time": "2023-06-14T09:14:34.863697Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_country_destinations_proba = pipeline.predict(model, X)\n",
    "\n",
    "classes = model.classes_\n",
    "predicted_classes = np.argmax(predicted_country_destinations_proba, axis=1)\n",
    "class_proba = np.max(predicted_country_destinations_proba, axis=1)\n",
    "predicted_class_names = [classes[i] for i in predicted_classes]\n",
    "\n",
    "df['country_destination'] = predicted_class_names\n",
    "df['proba'] = class_proba\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
